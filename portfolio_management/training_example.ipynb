{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.dpm_agent import Agent\r\n",
    "from trading_env.environment import TradingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_file = \"./data/archive_data/yf_data.dill\"\n",
    "with open(yf_file,'rb') as dill_file:\n",
    "    yf_df = dill.load(dill_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = yf_df['Symbol'].unique()\n",
    "stocks = []\n",
    "for symbol in symbols:\n",
    "    df = yf_df[yf_df['Symbol'] == symbol]\n",
    "    stocks.append(df.iloc[:,2:6].to_numpy())\n",
    "stocks = np.array(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, validation, and testing sets\r\n",
    "\r\n",
    "n_total_data = stocks.shape[1]\r\n",
    "\r\n",
    "split = [int(n_total_data*0.80),int(n_total_data*0.90)]\r\n",
    "split_data = np.split(stocks,split,axis=1)\r\n",
    "\r\n",
    "training_data = split_data[0]\r\n",
    "validation_data = split_data[1]\r\n",
    "test_data = split_data[2]\r\n",
    "\r\n",
    "# Save testing set\r\n",
    "with open('test_data.dill','wb') as dill_file:\r\n",
    "    dill.dump(test_data,dill_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 4227, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the data\r\n",
    "data_len = training_data.shape[1]\r\n",
    "div = list(map(int,np.linspace(0,data_len,41)))\r\n",
    "batched_training_data = np.split(stocks,div[1:-1],axis=1)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks = stocks.shape[0]\r\n",
    "n_stock_feats = stocks.shape[2]\r\n",
    "\r\n",
    "agent = Agent(n_stocks,n_stock_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained portfolio end value:\n",
      "tf.Tensor(957549.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "env = TradingEnv(batched_training_data[0])\r\n",
    "obs = env.reset()\r\n",
    "done = False\r\n",
    "last_raw_action = tf.zeros((1,n_stocks+1))\r\n",
    "while not done:\r\n",
    "    raw_action = agent.act(obs,last_raw_action) \r\n",
    "    obs, reward, done, _ = env.step(agent.model.softmax_layer(raw_action))\r\n",
    "    last_raw_action = raw_action \r\n",
    "print('Untrained portfolio end value:')\r\n",
    "print(env.portfolio_value_hist[-1])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 105, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_training_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_val(stock_data):\r\n",
    "    total_loss = tf.convert_to_tensor(0.0)\r\n",
    "    env = TradingEnv(stock_data)\r\n",
    "    obs = env.reset()\r\n",
    "    done = False\r\n",
    "    last_raw_action = tf.zeros((1,n_stocks+1))\r\n",
    "    while not done:\r\n",
    "\r\n",
    "        raw_action=agent.act(obs,last_raw_action)\r\n",
    "        obs,reward,done,_=env.step(agent.model.softmax_layer(raw_action))\r\n",
    "        last_raw_action=raw_action\r\n",
    "        total_loss-=reward\r\n",
    "\r\n",
    "    return total_loss, env\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\r\n",
    "time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "validation_log_dir = 'logs/grad_tape/'+time+'/valid'\r\n",
    "validation_summary_writer = tf.summary.create_file_writer(validation_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1501730.2, shape=(), dtype=float32)\n",
      "tf.Tensor(1465503.1, shape=(), dtype=float32)\n",
      "tf.Tensor(1457917.5, shape=(), dtype=float32)\n",
      "tf.Tensor(1456738.4, shape=(), dtype=float32)\n",
      "tf.Tensor(1455627.2, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "validation_loss = tf.keras.metrics.Mean('validation_loss', dtype=tf.float32)\r\n",
    "EPOCHS = 5\r\n",
    "\r\n",
    "for epoch in range(EPOCHS):\r\n",
    "\r\n",
    "    for batch in batched_training_data:\r\n",
    "        # Train on current batch\r\n",
    "        with tf.GradientTape() as tape:\r\n",
    "            tape.watch(agent.model.trainable_variables)\r\n",
    "            loss, env = loss_val(batch)\r\n",
    "        grad = tape.gradient(loss,agent.model.trainable_variables)\r\n",
    "        grad = [g / tf.reduce_mean(tf.abs(g)) for g in grad]\r\n",
    "        agent.opt.apply_gradients(zip(grad,agent.model.trainable_variables))\r\n",
    "\r\n",
    "    # Evaluate performance on validation set:\r\n",
    "    loss,env = loss_val(validation_data)\r\n",
    "    print(env.portfolio_value_hist[-1])\r\n",
    "    validation_loss(loss)\r\n",
    "    with validation_summary_writer.as_default():\r\n",
    "        tf.summary.scalar('loss',validation_loss.result(),step = epoch)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\r\n",
    "#%tensorboard  --logdir logs/grad_tape/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fd04f7af2b494cfcb6f7f88dc7e2e0996fcff442ebb77a6d3107b9d139ab71e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}