{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.dpm_agent import Agent\r\n",
    "from trading_env.environment import TradingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "#from IPython.core.interactiveshell import InteractiveShell\r\n",
    "#InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_file = \"./data/archive_data/yf_data.dill\"\n",
    "with open(yf_file,'rb') as dill_file:\n",
    "    yf_df = dill.load(dill_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of data set:\n",
      "Tail of data set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjclose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110959</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>WMT</td>\n",
       "      <td>144.389999</td>\n",
       "      <td>143.179993</td>\n",
       "      <td>143.539993</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>3018200</td>\n",
       "      <td>142.344345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110960</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>WMT</td>\n",
       "      <td>145.300003</td>\n",
       "      <td>143.330002</td>\n",
       "      <td>144.039993</td>\n",
       "      <td>145.220001</td>\n",
       "      <td>6448300</td>\n",
       "      <td>144.050491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110961</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>WMT</td>\n",
       "      <td>145.850006</td>\n",
       "      <td>143.589996</td>\n",
       "      <td>145.639999</td>\n",
       "      <td>144.300003</td>\n",
       "      <td>5979400</td>\n",
       "      <td>143.137909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110962</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>145.149994</td>\n",
       "      <td>143.940002</td>\n",
       "      <td>144.880005</td>\n",
       "      <td>144.179993</td>\n",
       "      <td>6250400</td>\n",
       "      <td>143.018860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110963</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>WMT</td>\n",
       "      <td>144.270004</td>\n",
       "      <td>142.850006</td>\n",
       "      <td>144.199997</td>\n",
       "      <td>144.149994</td>\n",
       "      <td>5938000</td>\n",
       "      <td>142.989090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Symbol        high         low        open       close  \\\n",
       "110959 2020-12-24    WMT  144.389999  143.179993  143.539993  143.500000   \n",
       "110960 2020-12-28    WMT  145.300003  143.330002  144.039993  145.220001   \n",
       "110961 2020-12-29    WMT  145.850006  143.589996  145.639999  144.300003   \n",
       "110962 2020-12-30    WMT  145.149994  143.940002  144.880005  144.179993   \n",
       "110963 2020-12-31    WMT  144.270004  142.850006  144.199997  144.149994   \n",
       "\n",
       "         volume    adjclose  \n",
       "110959  3018200  142.344345  \n",
       "110960  6448300  144.050491  \n",
       "110961  5979400  143.137909  \n",
       "110962  6250400  143.018860  \n",
       "110963  5938000  142.989090  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Head of data set:')\r\n",
    "yf_df.head()\r\n",
    "print('Tail of data set:')\r\n",
    "yf_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate array of symbols in the yf dataframe\r\n",
    "symbols = yf_df['Symbol'].unique()\r\n",
    "\r\n",
    "# Create empty lists to gather data\r\n",
    "training_data = []\r\n",
    "training_start = '2000-1-1'\r\n",
    "training_end = '2016-12-31'\r\n",
    "training_mask = (yf_df['Date'] >= training_start) & (yf_df['Date'] <= training_end)\r\n",
    "validation_data = []\r\n",
    "validation_start = '2017-1-1'\r\n",
    "validation_end = '2018-12-31'\r\n",
    "validation_mask = (yf_df['Date'] >= validation_start) & (yf_df['Date'] <= validation_end)\r\n",
    "test_data = []\r\n",
    "test_start = '2019-1-1'\r\n",
    "test_end = '2020-12-31'\r\n",
    "test_mask = (yf_df['Date'] >= test_start) & (yf_df['Date'] <= test_end)\r\n",
    "\r\n",
    "for symbol in symbols:\r\n",
    "    # Select stock data for each symbol,\r\n",
    "    # partition into training, validation, or test set\r\n",
    "    df_train = yf_df[(yf_df['Symbol'] == symbol) & training_mask]\r\n",
    "    df_validation = yf_df[(yf_df['Symbol'] == symbol) & validation_mask]\r\n",
    "    df_test = yf_df[(yf_df['Symbol'] == symbol) & test_mask]\r\n",
    "    \r\n",
    "    # Select only high, low, open, and close prices for each stock\r\n",
    "    training_data.append(df_train.iloc[:,2:6].to_numpy())\r\n",
    "    validation_data.append(df_validation.iloc[:,2:6].to_numpy())\r\n",
    "    test_data.append(df_test.iloc[:,2:6].to_numpy())\r\n",
    "     \r\n",
    "# Convert data to numpy arrays\r\n",
    "training_data = np.array(training_data)\r\n",
    "validation_data = np.array(validation_data)\r\n",
    "test_data = np.array(test_data)\r\n",
    "\r\n",
    "# Save the test data for post training\r\n",
    "with open('test_data.dill','wb') as dill_file:\r\n",
    "    dill.dump(test_data,dill_file)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 4277, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the data\r\n",
    "data_len = training_data.shape[1]\r\n",
    "div = list(map(int,np.linspace(0,data_len,41)))\r\n",
    "batched_training_data = np.split(training_data,div[1:-1],axis=1)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DPM agent for training\r\n",
    "n_stocks = training_data.shape[0]\r\n",
    "n_stock_feats = training_data.shape[2]\r\n",
    "\r\n",
    "agent = Agent(n_stocks,n_stock_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TradingEnv(validation_data)\r\n",
    "obs = env.reset()\r\n",
    "done = False\r\n",
    "last_raw_action = tf.zeros((1,n_stocks+1))\r\n",
    "while not done:\r\n",
    "    raw_action = agent.act(obs,last_raw_action) \r\n",
    "    obs, reward, done, _ = env.step(agent.model.softmax_layer(raw_action))\r\n",
    "    last_raw_action = raw_action \r\n",
    "print('Untrained portfolio end value:')\r\n",
    "print(env.portfolio_value_hist[-1])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_training_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_val(stock_data):\r\n",
    "    total_loss = tf.convert_to_tensor(0.0)\r\n",
    "    env = TradingEnv(stock_data)\r\n",
    "    obs = env.reset()\r\n",
    "    done = False\r\n",
    "    last_raw_action = tf.zeros((1,n_stocks+1))\r\n",
    "    while not done:\r\n",
    "\r\n",
    "        raw_action=agent.act(obs,last_raw_action)\r\n",
    "        obs,reward,done,_=env.step(agent.model.softmax_layer(raw_action))\r\n",
    "        last_raw_action=raw_action\r\n",
    "        total_loss-=reward\r\n",
    "\r\n",
    "    return total_loss, env\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\r\n",
    "time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "validation_log_dir = 'logs/grad_tape/'+time+'/valid'\r\n",
    "validation_summary_writer = tf.summary.create_file_writer(validation_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loss = tf.keras.metrics.Mean('validation_loss', dtype=tf.float32)\r\n",
    "EPOCHS = 5\r\n",
    "\r\n",
    "for epoch in range(EPOCHS):\r\n",
    "\r\n",
    "    for batch in batched_training_data:\r\n",
    "        # Train on current batch\r\n",
    "        with tf.GradientTape() as tape:\r\n",
    "            tape.watch(agent.model.trainable_variables)\r\n",
    "            loss, env = loss_val(batch)\r\n",
    "        grad = tape.gradient(loss,agent.model.trainable_variables)\r\n",
    "        grad = [g / tf.reduce_mean(tf.abs(g)) for g in grad]\r\n",
    "        agent.opt.apply_gradients(zip(grad,agent.model.trainable_variables))\r\n",
    "\r\n",
    "    # Evaluate performance on validation set:\r\n",
    "    loss,env = loss_val(validation_data)\r\n",
    "    print(env.portfolio_value_hist[-1])\r\n",
    "    validation_loss(loss)\r\n",
    "    with validation_summary_writer.as_default():\r\n",
    "        tf.summary.scalar('loss',validation_loss.result(),step = epoch)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\r\n",
    "#%tensorboard  --logdir logs/grad_tape/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fd04f7af2b494cfcb6f7f88dc7e2e0996fcff442ebb77a6d3107b9d139ab71e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}