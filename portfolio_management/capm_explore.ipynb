{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from agents.capm_agent import CAPM_Agent\r\n",
    "from trading_env.environment import TradingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\r\n",
    "from scipy.optimize import LinearConstraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_file = \"./data/archive_data/yf_data.dill\"\r\n",
    "with open(yf_file,'rb') as dill_file:\r\n",
    "    yf_df = dill.load(dill_file)\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk free rate\r\n",
    "r = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = yf_df['Symbol'].unique()\r\n",
    "stocks = []\r\n",
    "for symbol in symbols:\r\n",
    "    df = yf_df[yf_df['Symbol'] == symbol]\r\n",
    "    stocks.append(df.iloc[:,2:6].to_numpy())\r\n",
    "stocks = np.array(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the data\r\n",
    "div = list(map(int,np.linspace(0,5284,51)))\r\n",
    "batched_data = np.split(stocks,div[1:-1],axis=1)\r\n",
    "\r\n",
    "# Segment batches into training batches, 1 validation batch, 1 testing batch \r\n",
    "training_stock_data = batched_data[:-2]\r\n",
    "validation_stock_data = batched_data[-2]\r\n",
    "test_stock_data = batched_data[-1]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 105, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_stock_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TradingEnv(training_stock_data[0])\r\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "capm_agent = CAPM_Agent(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.07273687e-16, 0.00000000e+00, 2.17202590e-01, 1.45250564e-01,\n",
       "       0.00000000e+00, 2.75295038e-03, 0.00000000e+00, 6.02742363e-17,\n",
       "       6.93796943e-17, 2.83258991e-01, 1.46950136e-17, 0.00000000e+00,\n",
       "       0.00000000e+00, 7.29093687e-17, 8.86724180e-02, 9.66632624e-17,\n",
       "       5.86467730e-02, 0.00000000e+00, 2.04215714e-01, 0.00000000e+00,\n",
       "       2.94117792e-17])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capm_agent.act(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = ((obs[:-1,1:,-1] - obs[:-1,:-1,-1])/obs[:-1,:-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = np.cov(K)\r\n",
    "sigma = np.diagonal(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(K,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sigma,mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ones = np.ones(21)\r\n",
    "I = np.eye(21)\r\n",
    "M = np.vstack((Ones,I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_constraint = LinearConstraint(Ones, [1], [1])\r\n",
    "ineq_constraint = LinearConstraint(I,21*[0],21*[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_constraint = LinearConstraint(M, [1]+21*[0], 22*[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_portfolio(w):\r\n",
    "    num = np.dot(w,mu) - r\r\n",
    "    denom = np.sqrt(np.matmul(np.matmul(w,Sigma),w))\r\n",
    "    return - num / denom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Ones / Ones.sum()\r\n",
    "\r\n",
    "res = minimize(market_portfolio, w, constraints=[eq_constraint,ineq_constraint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SigmaInv = np.linalg.inv(Sigma)\r\n",
    "Ones = np.ones(21)\r\n",
    "\r\n",
    "W = np.matmul((mu-r*Ones),SigmaInv)\r\n",
    "w = W / W.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_portfolio(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TradingEnv(training_stock_data[0])\r\n",
    "obs = env.reset()\r\n",
    "done = False\r\n",
    "last_raw_action = tf.zeros((1,n_stocks+1))\r\n",
    "while not done:\r\n",
    "    raw_action = agent.act(obs,last_raw_action) \r\n",
    "    obs, reward, done, _ = env.step(agent.model.softmax_layer(raw_action))\r\n",
    "    last_raw_action = raw_action \r\n",
    "print('Untrained portfolio end value:')\r\n",
    "print(env.portfolio_value_hist[-1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fd04f7af2b494cfcb6f7f88dc7e2e0996fcff442ebb77a6d3107b9d139ab71e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}